"""
Adversarial Testing API Routes

These routes expose the adversarial testing system via REST API.

WHY: Allows frontend or external tools to run adversarial tests on-demand,
get challenge queries, and view weakness reports.
"""

from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Optional, List
from dataclasses import asdict

from core.adversarial import AdversarialTester

# Create router
router = APIRouter()

# Global adversarial tester instance (will be set by main.py)
_adversarial_tester: Optional[AdversarialTester] = None


def init_adversarial_tester(orchestrator):
    """
    Initialize the adversarial tester with the orchestrator instance.

    Call this from main.py after creating the orchestrator.
    """
    global _adversarial_tester
    _adversarial_tester = AdversarialTester(orchestrator)
    print("âœ“ Adversarial testing system initialized")


def get_adversarial_tester() -> AdversarialTester:
    """Get the adversarial tester instance (raises error if not initialized)"""
    if _adversarial_tester is None:
        raise HTTPException(
            status_code=500, detail="Adversarial tester not initialized"
        )
    return _adversarial_tester


# Request/Response models


class TestRequest(BaseModel):
    """Request to run a single adversarial test"""

    query: str


class ChallengeQuery(BaseModel):
    """A single challenge query"""

    query: str
    type: str
    expected_categories: List[str]
    difficulty: str
    description: str


class ChallengesResponse(BaseModel):
    """Response with list of challenge queries"""

    challenges: List[ChallengeQuery]
    count: int


class TestResponse(BaseModel):
    """Response from running a test"""

    query: str
    passed: bool
    confidence: float
    weakness: Optional[str]
    recommendation: Optional[str]


# API Endpoints


@router.get("/challenges", response_model=ChallengesResponse)
async def get_challenge_queries(regenerate: bool = False):
    """
    Get adversarial challenge queries generated by Gemini AI.

    These are challenging queries designed to expose LLM weaknesses:
    - Cross-domain queries that combine multiple topics
    - Edge cases that test boundary conditions
    - Multi-hop queries requiring complex reasoning

    Args:
        regenerate: Force regeneration of queries (default: use cached)

    Returns:
        List of challenge queries with descriptions

    WHY: Shows enterprises proactive testing before deploying to production.
    Frontend can display these as "What we're testing" in the dashboard.
    """
    try:
        tester = get_adversarial_tester()
        queries = tester.get_challenge_queries(regenerate=regenerate)

        # Convert dataclasses to dicts
        challenges = [
            ChallengeQuery(
                query=q.query,
                type=q.type,
                expected_categories=q.expected_categories,
                difficulty=q.difficulty,
                description=q.description,
            )
            for q in queries
        ]

        return ChallengesResponse(challenges=challenges, count=len(challenges))

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get challenges: {str(e)}")


@router.post("/test", response_model=TestResponse)
async def run_adversarial_test(request: TestRequest):
    """
    Run a single adversarial test query.

    Executes the query through the RAG system and analyzes the result.
    If the confidence is low, uses Gemini to analyze WHY and suggest improvements.

    Args:
        request: Test request with query to run

    Returns:
        Test result with pass/fail, confidence, and recommendations

    WHY: Allows running specific test cases and getting detailed failure analysis.
    Perfect for demos - you can show a failing test and the AI-powered recommendation.
    """
    try:
        tester = get_adversarial_tester()
        result = tester.run_test(request.query)

        return TestResponse(
            query=result.query,
            passed=result.passed,
            confidence=result.confidence,
            weakness=result.weakness_detected,
            recommendation=result.recommendation,
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Test failed: {str(e)}")


@router.get("/report")
async def get_adversarial_report():
    """
    Run full adversarial test suite and get comprehensive report.

    Executes all challenge queries and generates a detailed report including:
    - Pass/fail statistics
    - Weaknesses detected (queries with low confidence)
    - Failure patterns (grouped by query type)
    - AI-powered recommendations for improvements

    Returns:
        Comprehensive adversarial testing report

    WHY: This is the "one-click health check" for your LLM. Run this before
    deploying to production to find weaknesses. Perfect for demo - shows
    proactive testing in action.

    NOTE: This endpoint can take 30-60 seconds to complete (runs multiple tests).
    Consider making it async or running in background for production.
    """
    try:
        tester = get_adversarial_tester()
        report = tester.run_full_suite()
        return report

    except Exception as e:
        raise HTTPException(
            status_code=500, detail=f"Failed to generate report: {str(e)}"
        )


@router.post("/run-suite")
async def run_adversarial_suite():
    """
    Alias for /report - runs full test suite.

    Same as GET /report but uses POST for semantics (triggers action).
    Some teams prefer POST for operations that take time and generate reports.
    """
    return await get_adversarial_report()


@router.get("/health")
async def adversarial_health():
    """
    Check if adversarial testing system is operational.

    Returns status of Gemini API availability and system readiness.
    """
    try:
        tester = get_adversarial_tester()

        # Check if Gemini is available
        gemini_status = (
            "available"
            if tester.generator.gemini_available
            else "unavailable (using fallback)"
        )

        return {
            "status": "operational",
            "gemini_api": gemini_status,
            "cached_queries": len(tester._challenge_queries)
            if tester._challenge_queries
            else 0,
            "message": "Adversarial testing system ready",
        }

    except Exception as e:
        return {
            "status": "error",
            "message": str(e),
        }
